we want to show how much classes have been "moved" by the attack

- get 100 samples from each class
- for all layers: forward to layer, then dump latents instead of linear probe -> stack latents for all images
- repeat also with perturbed images (masks)

plot:

- make tsne / umap plot
- only fit to unperturbed images, not to perturbed images: https://umap-learn.readthedocs.io/en/latest/transform.html
- use color/shape to encode whether they're perturbed/unperturbed and the class
