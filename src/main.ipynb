{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YFmbVrfB2-O"
   },
   "source": [
    "We start from an Imagenet-pretrained ResNet152, replace its first and last layers, make it ready to use multi-resolution inputs generated from a single image, and finetune on CIFAR-100.\n",
    "\n",
    "We then train separate linear layers for each of the intermediate representations on top of a frozen backbone model.\n",
    "\n",
    "From these, we form a self-ensemble. We evalaute its adversarial accuracy on CIFAR-100 using the RobustBench AutoAttack at the end (with the `rand` flag enable).\n",
    "\n",
    "The whole Colab should take ~60 minutes on an A100 GPU and should be self-contained.\n",
    "\n",
    "It should give you above/about SOTA adversarial robustness on CIFAR-100 under $L_\\infty = 8/255$ attacks already, visualize the successfully attacked images and also visualize the class prototypes optimized directly from pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!pip install torch torchvision numpy tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZiyuMSC4Pwui"
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import json\n",
    "import copy\n",
    "import hashlib\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import resnet152\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import random\n",
    "import hashlib\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import contextmanager\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "#\n",
    "# config\n",
    "#\n",
    "\n",
    "classes_path = Path.cwd().parent / \"data\"\n",
    "dataset_path = Path.cwd().parent / \"datasets\"\n",
    "weights_path = Path.cwd().parent / \"weights\"\n",
    "\n",
    "os.makedirs(classes_path, exist_ok=True)\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "os.makedirs(weights_path, exist_ok=True)\n",
    "\n",
    "#\n",
    "# seed\n",
    "#\n",
    "\n",
    "# seed = 41\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def isolated_environment():\n",
    "    # save and restore random states in a context manager\n",
    "    # used to separate random-seed-fixing behavior from the attacks later\n",
    "    np_random_state = np.random.get_state()\n",
    "    python_random_state = random.getstate()\n",
    "    torch_random_state = torch.get_rng_state()\n",
    "    cuda_random_state = torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None\n",
    "    numpy_print_options = np.get_printoptions()\n",
    "    try:\n",
    "        yield  # execute code block\n",
    "    finally:\n",
    "        np.random.set_state(np_random_state)\n",
    "        random.setstate(python_random_state)\n",
    "        torch.set_rng_state(torch_random_state)\n",
    "        if cuda_random_state:\n",
    "            torch.cuda.set_rng_state_all(cuda_random_state)\n",
    "        np.set_printoptions(**numpy_print_options)\n",
    "\n",
    "\n",
    "#\n",
    "# data\n",
    "#\n",
    "\n",
    "classes = 100\n",
    "\n",
    "if classes == 10:\n",
    "    trainset = datasets.CIFAR10(root=dataset_path, train=True, download=True)\n",
    "    testset = datasets.CIFAR10(root=dataset_path, train=False, download=True)\n",
    "    original_images_train_np = np.array(trainset.data)\n",
    "    original_labels_train_np = np.array(trainset.targets)\n",
    "    original_images_test_np = np.array(testset.data)\n",
    "    original_labels_test_np = np.array(testset.targets)\n",
    "    classes_cifar10 = json.loads((classes_path / \"cifar10_classes.json\").read_text())\n",
    "elif classes == 100:\n",
    "    trainset = datasets.CIFAR100(root=dataset_path, train=True, download=True)\n",
    "    testset = datasets.CIFAR100(root=dataset_path, train=False, download=True)\n",
    "    original_images_train_np = np.array(trainset.data)\n",
    "    original_labels_train_np = np.array(trainset.targets)\n",
    "    original_images_test_np = np.array(testset.data)\n",
    "    original_labels_test_np = np.array(testset.targets)\n",
    "    classes_cifar100 = json.loads((classes_path / \"cifar100_classes.json\").read_text())\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "images_train_np = original_images_train_np / 255.0  # scale to [0, 1]\n",
    "images_test_np = original_images_test_np / 255.0\n",
    "labels_train_np = original_labels_train_np\n",
    "labels_test_np = original_labels_test_np\n",
    "\n",
    "#\n",
    "# multi resolution preprocessing (channel layer)\n",
    "#\n",
    "\n",
    "\n",
    "def custom_rand(input_tensor, size):\n",
    "    return torch.Tensor(np.random.rand(*size)).to(\"cuda\")\n",
    "\n",
    "\n",
    "def custom_choices(items, tensor):\n",
    "    return np.random.choice(items, (len(tensor)))\n",
    "\n",
    "\n",
    "resolutions = [32, 16, 8, 4]  # pretty arbitrary\n",
    "shuffle_image_versions_randomly = False  # to shuffle randomly which image is which in the multi-res stack (false in paper)\n",
    "transform = True  # to apply the transformations or not (true in paper)\n",
    "\n",
    "\n",
    "def default_make_multichannel_input(images):\n",
    "    return torch.concatenate([images] * len(resolutions), axis=1)\n",
    "\n",
    "\n",
    "def apply_transformations(images, down_res, up_res, jit_x, jit_y, down_noise, up_noise, contrast, color_amount):\n",
    "    # images = torch.mean(images,axis=1,keepdims=True) # for MNIST alone\n",
    "\n",
    "    images_collected = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image = images[i]\n",
    "        image = torchvision.transforms.functional.adjust_contrast(image, contrast[i])  # changing contrast\n",
    "        image = torch.roll(image, shifts=(jit_x[i], jit_y[i]), dims=(-2, -1))  # shift the result in x and y\n",
    "        image = color_amount[i] * image + torch.mean(image, axis=0, keepdims=True) * (1 - color_amount[i])  # shifting in the color <-> grayscale axis\n",
    "        images_collected.append(image)\n",
    "\n",
    "    images = torch.stack(images_collected, axis=0)\n",
    "\n",
    "    images = F.interpolate(images, size=(down_res, down_res), mode=\"bicubic\")  # descrease the resolution\n",
    "    noise = down_noise * custom_rand(images + 312, (images.shape[0], 3, down_res, down_res)).to(\"cuda\")  # low res noise\n",
    "    images = images + noise\n",
    "\n",
    "    images = F.interpolate(images, size=(up_res, up_res), mode=\"bicubic\")  # increase the resolution\n",
    "    noise = up_noise * custom_rand(images + 812, (images.shape[0], 3, up_res, up_res)).to(\"cuda\")  # high res noise\n",
    "    images = images + noise\n",
    "\n",
    "    images = torch.clip(images, 0, 1)  # clipping to the right range of values\n",
    "    return images\n",
    "\n",
    "\n",
    "def make_multichannel_input(images):\n",
    "    all_channels = []\n",
    "    if transform:\n",
    "        for i, r in enumerate(resolutions):\n",
    "            jit_size = 3  # max size of the x-y jit in each axis, sampled uniformly from -jit_size to +jit_size inclusive\n",
    "            images_now = apply_transformations(\n",
    "                images,\n",
    "                down_res=r,\n",
    "                up_res=32,  # hard coded for CIFAR-10 or CIFAR-100\n",
    "                jit_x=custom_choices(range(-jit_size, jit_size + 1), images + i),  # x-shift\n",
    "                jit_y=custom_choices(range(-jit_size, jit_size + 1), 51 * images + 7 * i + 125 * r),  # y-shift\n",
    "                down_noise=0.2,  # noise standard deviation to be added at the low resolution\n",
    "                up_noise=0.2,  # noise stadard deviation to be added at the high resolution\n",
    "                contrast=custom_choices(np.linspace(0.5, 1.0, 100), 5 + 7 * images + 8 * i + 2 * r),  # change in contrast\n",
    "                color_amount=custom_choices(np.linspace(0.5, 1.0, 100), 5 + 7 * images + 8 * i + 2 * r),  # change in color amount\n",
    "            )\n",
    "            all_channels.append(images_now)\n",
    "    else:\n",
    "        all_channels = [images] * len(resolutions)\n",
    "\n",
    "    if not shuffle_image_versions_randomly:\n",
    "        return torch.concatenate(all_channels, axis=1)\n",
    "    elif shuffle_image_versions_randomly:\n",
    "        indices = torch.randperm(len(all_channels))\n",
    "        shuffled_tensor_list = [all_channels[i] for i in indices]\n",
    "        return torch.concatenate(shuffled_tensor_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "sample_images = images_test_np[:5]\n",
    "\n",
    "for j in [0, 1]:\n",
    "    multichannel_images = make_multichannel_input(torch.Tensor(sample_images.transpose([0, 3, 1, 2])).to(\"cuda\")).detach().cpu().numpy().transpose([0, 2, 3, 1])\n",
    "\n",
    "    N = 1 + multichannel_images.shape[3] // 3\n",
    "\n",
    "    plt.figure(figsize=(N * 5.5, 5))\n",
    "\n",
    "    plt.subplot(1, N, 1)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(sample_images[j])\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        plt.subplot(1, N, i + 2)\n",
    "        plt.title(f\"res={resolutions[i]}\")\n",
    "        plt.imshow(multichannel_images[j, :, :, 3 * i : 3 * (i + 1)])\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, images_in, labels_in, batch_size=128):\n",
    "    all_preds = []\n",
    "    all_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        its = int(np.ceil(float(len(images_in)) / float(batch_size)))\n",
    "\n",
    "        pbar = tqdm(range(its), desc=\"Eval\", ncols=100)\n",
    "\n",
    "        for it in pbar:\n",
    "            i1 = it * batch_size\n",
    "            i2 = min([(it + 1) * batch_size, len(images_in)])\n",
    "\n",
    "            inputs = torch.Tensor(images_in[i1:i2].transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            all_logits.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "            preds = torch.argmax(outputs, axis=-1)\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "\n",
    "    return np.sum(all_preds == labels_in), all_preds.shape[0], all_logits\n",
    "\n",
    "\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "imported_model = resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# fixed for ResNet152 first conv layer, change for others by hand\n",
    "in_planes = 3\n",
    "planes = 64\n",
    "stride = 2\n",
    "N = len(resolutions)  # input channels multiplier due to multi-res input\n",
    "\n",
    "conv2 = nn.Conv2d(N * in_planes, planes, kernel_size=7, stride=stride, padding=3, bias=False)\n",
    "\n",
    "# replacing the pretrained conv with new init of the multi-res one\n",
    "imported_model.conv1 = copy.deepcopy(conv2)\n",
    "\n",
    "# getting the final layer to predcit the right number of classes -> new init\n",
    "imported_model.fc = nn.Linear(2048, classes)\n",
    "\n",
    "\n",
    "class ImportedModelWrapper(nn.Module):\n",
    "    def __init__(self, imported_model, multichannel_fn):\n",
    "        super(ImportedModelWrapper, self).__init__()\n",
    "        self.imported_model = imported_model\n",
    "        self.multichannel_fn = multichannel_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.multichannel_fn(x)\n",
    "        x = F.interpolate(x, size=(224, 224), mode=\"bicubic\")\n",
    "        x = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406] * (x.shape[1] // 3), std=[0.229, 0.224, 0.225] * (x.shape[1] // 3))(x)\n",
    "        x = self.imported_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "wrapped_model = ImportedModelWrapper(imported_model, make_multichannel_input).to(\"cuda\")\n",
    "wrapped_model.multichannel_fn = make_multichannel_input\n",
    "\n",
    "\n",
    "# to get light adversarial training going, off by default\n",
    "def fgsm_attack(model, xs, ys, epsilon, random_reps=1, batch_size=64):\n",
    "    model = model.eval()\n",
    "\n",
    "    its = int(np.ceil(xs.shape[0] / batch_size))\n",
    "\n",
    "    all_perturbed_images = []\n",
    "\n",
    "    for it in range(its):\n",
    "        i1 = it * batch_size\n",
    "        i2 = min([(it + 1) * batch_size, xs.shape[0]])\n",
    "\n",
    "        x = torch.Tensor(xs[i1:i2].transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "        y = torch.Tensor(ys[i1:i2]).to(\"cuda\").to(torch.long)\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        for _ in range(random_reps):\n",
    "            outputs = model(x)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, y)\n",
    "            loss.backward()\n",
    "\n",
    "        perturbed_image = x + epsilon * x.grad.data.sign()\n",
    "        perturbed_image = torch.clip(perturbed_image, 0, 1)\n",
    "\n",
    "        all_perturbed_images.append(perturbed_image.detach().cpu().numpy().transpose([0, 2, 3, 1]))\n",
    "\n",
    "    return np.concatenate(all_perturbed_images, axis=0)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model_in,\n",
    "    images_in,\n",
    "    labels_in,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    batch_size=512,\n",
    "    optimizer_in=optim.Adam,\n",
    "    subset_only=None,\n",
    "    mode=\"eval\",\n",
    "    use_adversarial_training=False,\n",
    "    adversarial_epsilon=8 / 255,\n",
    "    skip_test_set_eval=False,\n",
    "):\n",
    "    global storing_models\n",
    "\n",
    "    if mode == \"train\":\n",
    "        model_in.train()\n",
    "    elif mode == \"eval\":\n",
    "        model_in.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if subset_only is None:\n",
    "        train_optimizer = optimizer_in(model_in.parameters(), lr=lr)\n",
    "    else:\n",
    "        train_optimizer = optimizer_in(subset_only, lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        randomized_ids = np.random.permutation(range(len(images_in)))\n",
    "\n",
    "        # making sure the model is in the right eval/train mode every epoch\n",
    "        # due to the potential switching by black-box evals applied\n",
    "        if mode == \"train\":\n",
    "            model_in.train()\n",
    "        elif mode == \"eval\":\n",
    "            model_in.eval()\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        its = int(np.ceil(float(len(images_in)) / float(batch_size)))\n",
    "        pbar = tqdm(range(its), desc=\"Training\", ncols=100)\n",
    "\n",
    "        all_hits = []\n",
    "\n",
    "        for it in pbar:\n",
    "            i1 = it * batch_size\n",
    "            i2 = min([(it + 1) * batch_size, len(images_in)])\n",
    "\n",
    "            ids_now = randomized_ids[i1:i2]\n",
    "\n",
    "            np_images_used = images_in[ids_now]\n",
    "            np_labels_used = labels_in[ids_now]\n",
    "\n",
    "            inputs = torch.Tensor(np_images_used.transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "\n",
    "            # very light adversarial training if on\n",
    "            if use_adversarial_training:\n",
    "                attacked_images = fgsm_attack(\n",
    "                    model_in.eval(),\n",
    "                    np_images_used[:],\n",
    "                    np_labels_used[:],\n",
    "                    epsilon=adversarial_epsilon,\n",
    "                    random_reps=1,\n",
    "                    batch_size=batch_size // 2,\n",
    "                )\n",
    "                np_images_used = attacked_images\n",
    "                np_labels_used = np_labels_used\n",
    "\n",
    "                if mode == \"train\":\n",
    "                    model_in.train()\n",
    "                elif mode == \"eval\":\n",
    "                    model_in.eval()\n",
    "\n",
    "            inputs = torch.Tensor(np_images_used.transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "            labels = torch.Tensor(np_labels_used).to(\"cuda\").to(torch.long)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            train_optimizer.zero_grad()\n",
    "\n",
    "            inputs_used = inputs\n",
    "\n",
    "            # the actual optimization step\n",
    "            outputs = model_in(inputs_used)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_optimizer.step()\n",
    "\n",
    "            # on the fly eval for the train set batches\n",
    "            preds = torch.argmax(outputs, axis=-1)\n",
    "            acc = torch.mean((preds == labels).to(torch.float), axis=-1)\n",
    "            all_hits.append((preds == labels).to(torch.float).detach().cpu().numpy())\n",
    "            train_accs.append(acc.detach().cpu().numpy())\n",
    "\n",
    "            pbar.set_description(f\"train acc={acc.detach().cpu().numpy()} loss={loss.item()}\")\n",
    "\n",
    "        if not skip_test_set_eval:\n",
    "            with isolated_environment():\n",
    "                eval_model_copy = copy.deepcopy(model_in)\n",
    "                test_hits, test_count, _ = eval_model(eval_model_copy.eval(), images_test_np, labels_test_np)\n",
    "        else:\n",
    "            # to avoid dividing by zero\n",
    "            test_hits = 0\n",
    "            test_count = 1\n",
    "\n",
    "        # end of epoch eval\n",
    "        train_hits = np.sum(np.concatenate(all_hits, axis=0).reshape([-1]))\n",
    "        train_count = np.concatenate(all_hits, axis=0).reshape([-1]).shape[0]\n",
    "        print(f\"e={epoch} train {train_hits} / {train_count} = {train_hits/train_count},  test {test_hits} / {test_count} = {test_hits/test_count}\")\n",
    "\n",
    "        test_accs.append(test_hits / test_count)\n",
    "\n",
    "    print(\"\\nFinished Training\")\n",
    "\n",
    "    return model_in\n",
    "\n",
    "\n",
    "lr = 3.3e-5  # found with very simple \"grid search\" by hand, likely not optimal!\n",
    "mode = \"train\"\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "model = copy.deepcopy(wrapped_model)\n",
    "model.multichannel_fn = make_multichannel_input\n",
    "\n",
    "if mode == \"eval\":\n",
    "    model = model.eval()\n",
    "elif mode == \"train\":\n",
    "    model = model.train()\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# with torch.autocast(\"cuda\"):\n",
    "model = train_model(\n",
    "    model,\n",
    "    images_train_np,\n",
    "    labels_train_np,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    optimizer_in=optim.Adam,\n",
    "    batch_size=128,\n",
    "    mode=mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# model\n",
    "#\n",
    "\n",
    "imported_model = resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "imported_model.fc = nn.Linear(2048, classes)  # set num of classes\n",
    "\n",
    "# update first conv layer for multi-res\n",
    "in_planes = 3\n",
    "planes = 64\n",
    "stride = 2\n",
    "N = len(resolutions)  # input channels multiplier due to multi-res input\n",
    "conv2 = nn.Conv2d(N * in_planes, planes, kernel_size=7, stride=stride, padding=3, bias=False)\n",
    "imported_model.conv1 = copy.deepcopy(conv2)\n",
    "\n",
    "\n",
    "class ImportedModelWrapper(nn.Module):\n",
    "    def __init__(self, imported_model, multichannel_fn):\n",
    "        super(ImportedModelWrapper, self).__init__()\n",
    "        self.imported_model = imported_model\n",
    "        self.multichannel_fn = multichannel_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        # our custom preprocessing\n",
    "        x = self.multichannel_fn(x)\n",
    "        # default resnet preprocessing\n",
    "        x = F.interpolate(x, size=(224, 224), mode=\"bicubic\")\n",
    "        x = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406] * (x.shape[1] // 3), std=[0.229, 0.224, 0.225] * (x.shape[1] // 3))(x)\n",
    "        x = self.imported_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "wrapped_model = ImportedModelWrapper(imported_model, make_multichannel_input).to(\"cuda\")\n",
    "wrapped_model.multichannel_fn = make_multichannel_input\n",
    "model = copy.deepcopy(wrapped_model)\n",
    "model.multichannel_fn = make_multichannel_input\n",
    "model = model.train()\n",
    "\n",
    "#\n",
    "# train\n",
    "#\n",
    "\n",
    "\n",
    "def eval_model(model, images_in, labels_in, batch_size=128):\n",
    "    all_preds = []\n",
    "    all_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        its = int(np.ceil(float(len(images_in)) / float(batch_size)))\n",
    "        pbar = tqdm(range(its), desc=\"Eval\", ncols=100)\n",
    "        for it in pbar:\n",
    "            i1 = it * batch_size\n",
    "            i2 = min([(it + 1) * batch_size, len(images_in)])\n",
    "\n",
    "        inputs = torch.Tensor(images_in[i1:i2].transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "        outputs = model(inputs)\n",
    "        all_logits.append(outputs.detach().cpu().numpy())\n",
    "        preds = torch.argmax(outputs, axis=-1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "    return np.sum(all_preds == labels_in), all_preds.shape[0], all_logits\n",
    "\n",
    "\n",
    "def fgsm_attack(model, xs, ys, epsilon, random_reps=1, batch_size=64):  # optional light adv training (false in paper)\n",
    "    model = model.eval()\n",
    "    its = int(np.ceil(xs.shape[0] / batch_size))\n",
    "    all_perturbed_images = []\n",
    "    for it in range(its):\n",
    "        i1 = it * batch_size\n",
    "        i2 = min([(it + 1) * batch_size, xs.shape[0]])\n",
    "    x = torch.Tensor(xs[i1:i2].transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "    y = torch.Tensor(ys[i1:i2]).to(\"cuda\").to(torch.long)\n",
    "\n",
    "    x.requires_grad = True\n",
    "    for _ in range(random_reps):\n",
    "        outputs = model(x)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "    perturbed_image = x + epsilon * x.grad.data.sign()\n",
    "    perturbed_image = torch.clip(perturbed_image, 0, 1)\n",
    "    all_perturbed_images.append(perturbed_image.detach().cpu().numpy().transpose([0, 2, 3, 1]))\n",
    "    return np.concatenate(all_perturbed_images, axis=0)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    # model_in,\n",
    "    # images_in,\n",
    "    # labels_in,\n",
    "    # epochs = 10,\n",
    "    # lr = 1e-3,\n",
    "    # batch_size = 512,\n",
    "    # optimizer_in = optim.Adam,\n",
    "    # subset_only = None,\n",
    "    # mode = \"eval\",\n",
    "    # use_adversarial_training = False,\n",
    "    # adversarial_epsilon = 8/255,\n",
    "    # skip_test_set_eval = False,\n",
    "    model_in,\n",
    "    images_in,\n",
    "    labels_in,\n",
    "    epochs,\n",
    "    lr,\n",
    "    batch_size,\n",
    "    optimizer_in,\n",
    "    subset_only,\n",
    "    mode,\n",
    "    use_adversarial_training,\n",
    "    adversarial_epsilon,\n",
    "    skip_test_set_eval,\n",
    "):\n",
    "    global storing_models\n",
    "\n",
    "    if mode == \"train\":\n",
    "        model_in.train()\n",
    "    elif mode == \"eval\":\n",
    "        model_in.eval()\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if subset_only is None:\n",
    "        train_optimizer = optimizer_in(model_in.parameters(), lr=lr)\n",
    "    else:\n",
    "        train_optimizer = optimizer_in(subset_only, lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        randomized_ids = np.random.permutation(range(len(images_in)))\n",
    "        if mode == \"train\":  # bugfix\n",
    "            model_in.train()\n",
    "        elif mode == \"eval\":\n",
    "            model_in.eval()\n",
    "        its = int(np.ceil(float(len(images_in)) / float(batch_size)))\n",
    "        pbar = tqdm(range(its), desc=\"Training\", ncols=100)\n",
    "\n",
    "        all_hits = []\n",
    "        for it in pbar:\n",
    "            i1 = it * batch_size\n",
    "            i2 = min([(it + 1) * batch_size, len(images_in)])\n",
    "            ids_now = randomized_ids[i1:i2]\n",
    "            np_images_used = images_in[ids_now]\n",
    "            np_labels_used = labels_in[ids_now]\n",
    "\n",
    "            # light adversarial training\n",
    "            if use_adversarial_training:\n",
    "                inputs = torch.Tensor(np_images_used.transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "                attacked_images = fgsm_attack(model_in.eval(), np_images_used[:], np_labels_used[:], epsilon=adversarial_epsilon, random_reps=1, batch_size=batch_size // 2)\n",
    "                np_images_used = attacked_images\n",
    "                np_labels_used = np_labels_used\n",
    "                if mode == \"train\":\n",
    "                    model_in.train()\n",
    "                elif mode == \"eval\":\n",
    "                    model_in.eval()\n",
    "\n",
    "            # forward and optimize\n",
    "            inputs = torch.Tensor(np_images_used.transpose([0, 3, 1, 2])).to(\"cuda\")\n",
    "            labels = torch.Tensor(np_labels_used).to(\"cuda\").to(torch.long)\n",
    "            train_optimizer.zero_grad()\n",
    "            outputs = model_in(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_optimizer.step()\n",
    "\n",
    "            # eval on trainset\n",
    "            preds = torch.argmax(outputs, axis=-1)\n",
    "            acc = torch.mean((preds == labels).to(torch.float), axis=-1)\n",
    "            all_hits.append((preds == labels).to(torch.float).detach().cpu().numpy())\n",
    "            train_accs.append(acc.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"train acc={acc.detach().cpu().numpy()} loss={loss.item()}\")\n",
    "\n",
    "        # eval on testset\n",
    "        if not skip_test_set_eval:\n",
    "            with isolated_environment():\n",
    "                eval_model_copy = copy.deepcopy(model_in)\n",
    "                test_hits, test_count, _ = eval_model(eval_model_copy.eval(), images_test_np, labels_test_np)\n",
    "        train_hits = np.sum(np.concatenate(all_hits, axis=0).reshape([-1]))\n",
    "        train_count = np.concatenate(all_hits, axis=0).reshape([-1]).shape[0]\n",
    "        print(f\"e={epoch} train {train_hits} / {train_count} = {train_hits/train_count},  test {test_hits} / {test_count} = {test_hits/test_count}\")\n",
    "        test_accs.append((test_hits / test_count) if (not skip_test_set_eval and test_count > 0) else 0)\n",
    "    print(\"done\")\n",
    "    return model_in\n",
    "\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "with torch.autocast(\"cuda\"):\n",
    "    model = train_model(\n",
    "        model_in=model,\n",
    "        images_in=images_train_np,\n",
    "        labels_in=labels_train_np,\n",
    "        epochs=6,  # takes 2h on A100\n",
    "        lr=3.3e-5,  # likely not optimal\n",
    "        batch_size=128,\n",
    "        optimizer_in=optim.Adam,\n",
    "        subset_only=None,\n",
    "        mode=\"train\",\n",
    "        use_adversarial_training=False,\n",
    "        adversarial_epsilon=8 / 255,\n",
    "        skip_test_set_eval=False,\n",
    "    )\n",
    "\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOy7xTZTcy0op4Ph2y/HCG0",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
