{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to change as few lines as possible - while still getting it to run on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision numpy tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def free_mem(): # keep like prev version\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "free_mem()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"backend:native,max_split_size_mb:512,garbage_collection_threshold:0.8,expandable_segments:True\" # keep like prev version\n",
    "\n",
    "\n",
    "# \n",
    "# context manager\n",
    "# \n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def isolated_environment():\n",
    "    # Save the current state of random seeds and numpy precision\n",
    "    np_random_state = np.random.get_state()\n",
    "    python_random_state = random.getstate()\n",
    "    torch_random_state = torch.get_rng_state()\n",
    "    cuda_random_state = torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None\n",
    "    numpy_print_options = np.get_printoptions()\n",
    "    try:\n",
    "        # Execute the block of code\n",
    "        yield\n",
    "    finally:\n",
    "        # Restore the saved state\n",
    "        np.random.set_state(np_random_state)\n",
    "        random.setstate(python_random_state)\n",
    "        torch.set_rng_state(torch_random_state)\n",
    "        if cuda_random_state:\n",
    "            torch.cuda.set_rng_state_all(cuda_random_state)\n",
    "        np.set_printoptions(**numpy_print_options)\n",
    "\n",
    "\n",
    "#\n",
    "# data\n",
    "#\n",
    "\n",
    "\n",
    "classes_path = Path.cwd().parent / \"data\"\n",
    "dataset_path = Path.cwd().parent / \"datasets\"\n",
    "weights_path = Path.cwd().parent / \"weights\"\n",
    "\n",
    "os.makedirs(classes_path, exist_ok=True)\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "os.makedirs(weights_path, exist_ok=True)\n",
    "\n",
    "\n",
    "classes = 100\n",
    "assert classes == 100\n",
    "\n",
    "if classes == 10:\n",
    "    # Load the CIFAR-10 dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root=dataset_path, train=True, download=True)\n",
    "    testset = torchvision.datasets.CIFAR10(root=dataset_path, train=False, download=True)\n",
    "\n",
    "    original_images_train_np = np.array(trainset.data)\n",
    "    original_labels_train_np = np.array(trainset.targets)\n",
    "\n",
    "    original_images_test_np = np.array(testset.data)\n",
    "    original_labels_test_np = np.array(testset.targets)\n",
    "\n",
    "elif classes == 100:\n",
    "    # Load the CIFAR-100 dataset\n",
    "    trainset = torchvision.datasets.CIFAR100(root=dataset_path, train=True, download=True)\n",
    "    testset = torchvision.datasets.CIFAR100(root=dataset_path, train=False, download=True)\n",
    "\n",
    "    original_images_train_np = np.array(trainset.data)\n",
    "    original_labels_train_np = np.array(trainset.targets)\n",
    "\n",
    "    original_images_test_np = np.array(testset.data)\n",
    "    original_labels_test_np = np.array(testset.targets)\n",
    "\n",
    "else:\n",
    "    # assert False\n",
    "    # Load the MNIST dataset\n",
    "    trainset = torchvision.datasets.MNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "    )\n",
    "    testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "    original_images_train_np = np.array(trainset.data)\n",
    "    original_labels_train_np = np.array(trainset.targets)\n",
    "\n",
    "    original_images_train_np = np.stack([original_images_train_np] * 3, axis=3)\n",
    "\n",
    "    original_images_test_np = np.array(testset.data)\n",
    "    original_labels_test_np = np.array(testset.targets)\n",
    "\n",
    "    original_images_test_np = np.stack([original_images_test_np] * 3, axis=3)\n",
    "\n",
    "    classes = 10\n",
    "\n",
    "# images between 0 and 1 instead of 0 and 255\n",
    "\n",
    "images_train_np = original_images_train_np / 255.0\n",
    "images_test_np = original_images_test_np / 255.0\n",
    "\n",
    "labels_train_np = original_labels_train_np\n",
    "labels_test_np = original_labels_test_np\n",
    "\n",
    "\n",
    "#\n",
    "# preprocessing\n",
    "#\n",
    "\n",
    "\n",
    "# to be able to replace the random number generator by other things if needed\n",
    "def custom_rand(input_tensor, size):\n",
    "    return torch.Tensor(np.random.rand(*size)).to(\"cuda\")\n",
    "\n",
    "\n",
    "def custom_choices(items, tensor):\n",
    "    return np.random.choice(items, (len(tensor)))\n",
    "\n",
    "\n",
    "# apply image augmentations to input images\n",
    "def apply_transformations(\n",
    "    images,\n",
    "    down_res=224,\n",
    "    up_res=224,\n",
    "    jit_x=0,\n",
    "    jit_y=0,\n",
    "    down_noise=0.0,\n",
    "    up_noise=0.0,\n",
    "    contrast=1.0,\n",
    "    color_amount=1.0,\n",
    "):\n",
    "    # # for MNIST alone\n",
    "    # images = torch.mean(images,axis=1,keepdims=True)\n",
    "\n",
    "    images_collected = []\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        image = images[i]\n",
    "\n",
    "        # changing contrast\n",
    "        image = torchvision.transforms.functional.adjust_contrast(image, contrast[i])\n",
    "\n",
    "        # shift the result in x and y\n",
    "        image = torch.roll(image, shifts=(jit_x[i], jit_y[i]), dims=(-2, -1))\n",
    "\n",
    "        # shifting in the color <-> grayscale axis\n",
    "        image = color_amount[i] * image + torch.mean(image, axis=0, keepdims=True) * (1 - color_amount[i])\n",
    "\n",
    "        images_collected.append(image)\n",
    "\n",
    "    images = torch.stack(images_collected, axis=0)\n",
    "\n",
    "    # descrease the resolution\n",
    "    images = F.interpolate(images, size=(down_res, down_res), mode=\"bicubic\")\n",
    "\n",
    "    # low res noise\n",
    "    noise = down_noise * custom_rand(images + 312, (images.shape[0], 3, down_res, down_res)).to(\"cuda\")\n",
    "    images = images + noise\n",
    "\n",
    "    # increase the resolution\n",
    "    images = F.interpolate(images, size=(up_res, up_res), mode=\"bicubic\")\n",
    "\n",
    "    # high res noise\n",
    "    noise = up_noise * custom_rand(images + 812, (images.shape[0], 3, up_res, up_res)).to(\"cuda\")\n",
    "    images = images + noise\n",
    "\n",
    "    # clipping to the right range of values\n",
    "    images = torch.clip(images, 0, 1)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "resolutions = [32, 16, 8, 4]  # pretty arbitrary\n",
    "down_noise = 0.2  # noise standard deviation to be added at the low resolution\n",
    "up_noise = 0.2  # noise stadard deviation to be added at the high resolution\n",
    "jit_size = 3  # max size of the x-y jit in each axis, sampled uniformly from -jit_size to +jit_size inclusive\n",
    "\n",
    "# to shuffle randomly which image is which in the multi-res stack\n",
    "# False for all experiments in the paper, good for ablations\n",
    "shuffle_image_versions_randomly = False\n",
    "\n",
    "\n",
    "def default_make_multichannel_input(images):\n",
    "    return torch.concatenate([images] * len(resolutions), axis=1)\n",
    "\n",
    "\n",
    "def make_multichannel_input(\n",
    "    images,\n",
    "    contrast=1.0,\n",
    "    up_res=32,  # hard coded for CIFAR-10 or CIFAR-100\n",
    "):\n",
    "    all_channels = []\n",
    "\n",
    "    for i, r in enumerate(resolutions):\n",
    "        down_res = r\n",
    "\n",
    "        jits_x = custom_choices(range(-jit_size, jit_size + 1), images + i)  # x-shift\n",
    "        jits_y = custom_choices(range(-jit_size, jit_size + 1), 51 * images + 7 * i + 125 * r)  # y-shift\n",
    "        contrasts = custom_choices(np.linspace(0.7, 1.5, 100), 7 + 3 * images + 9 * i + 5 * r)  # change in contrast\n",
    "        color_amounts = contrasts = custom_choices(np.linspace(0.5, 1.0, 100), 5 + 7 * images + 8 * i + 2 * r)  # change in color amount\n",
    "\n",
    "        images_now = apply_transformations(\n",
    "            images,\n",
    "            down_res=down_res,\n",
    "            up_res=up_res,\n",
    "            jit_x=jits_x,\n",
    "            jit_y=jits_y,\n",
    "            down_noise=down_noise,\n",
    "            up_noise=up_noise,\n",
    "            contrast=contrasts,\n",
    "            color_amount=color_amounts,\n",
    "        )\n",
    "\n",
    "        all_channels.append(images_now)\n",
    "\n",
    "    if not shuffle_image_versions_randomly:\n",
    "        return torch.concatenate(all_channels, axis=1)\n",
    "    elif shuffle_image_versions_randomly:\n",
    "        indices = torch.randperm(len(all_channels))\n",
    "        shuffled_tensor_list = [all_channels[i] for i in indices]\n",
    "        return torch.concatenate(shuffled_tensor_list, axis=1)\n",
    "\n",
    "\n",
    "# sample_images = images_test_np[:5]\n",
    "\n",
    "# for j in [0, 1]:\n",
    "#     multichannel_images = (\n",
    "#         make_multichannel_input(\n",
    "#             torch.Tensor(sample_images.transpose([0, 3, 1, 2])).to(\"cuda\"),\n",
    "#         )\n",
    "#         .detach()\n",
    "#         .cpu()\n",
    "#         .numpy()\n",
    "#         .transpose([0, 2, 3, 1])\n",
    "#     )\n",
    "\n",
    "#     N = 1 + multichannel_images.shape[3] // 3\n",
    "\n",
    "#     plt.figure(figsize=(N * 5.5, 5))\n",
    "\n",
    "#     plt.subplot(1, N, 1)\n",
    "#     plt.title(\"original\")\n",
    "#     plt.imshow(sample_images[j])\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "\n",
    "#     for i in range(N - 1):\n",
    "#         plt.subplot(1, N, i + 2)\n",
    "#         plt.title(f\"res={resolutions[i]}\")\n",
    "#         plt.imshow(multichannel_images[j, :, :, 3 * i : 3 * (i + 1)])\n",
    "#         plt.xticks([], [])\n",
    "#         plt.yticks([], [])\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, device=\"cuda\"):\n",
    "        super(BatchNormLinear, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(in_features, device=device)\n",
    "        self.linear = nn.Linear(in_features, out_features, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class WrapModelForResNet152(torch.nn.Module):\n",
    "    def __init__(self, model, multichannel_fn, classes=10):\n",
    "        super(WrapModelForResNet152, self).__init__()\n",
    "\n",
    "        self.multichannel_fn = multichannel_fn\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.classes = classes\n",
    "\n",
    "        self.layer_operations = [\n",
    "            torch.nn.Sequential(\n",
    "                model.conv1,\n",
    "                model.bn1,\n",
    "                model.relu,\n",
    "                model.maxpool,\n",
    "            ),\n",
    "            *model.layer1,\n",
    "            *model.layer2,\n",
    "            *model.layer3,\n",
    "            *model.layer4,\n",
    "            model.avgpool,\n",
    "            model.fc,\n",
    "        ]\n",
    "\n",
    "        self.all_dims = [\n",
    "            3 * 224 * 224 * len(resolutions),\n",
    "            64 * 56 * 56,\n",
    "            *[256 * 56 * 56] * len(model.layer1),\n",
    "            *[512 * 28 * 28] * len(model.layer2),\n",
    "            *[1024 * 14 * 14] * len(model.layer3),\n",
    "            *[2048 * 7 * 7] * len(model.layer4),\n",
    "            2048,\n",
    "            1000,\n",
    "        ]\n",
    "\n",
    "        self.linear_layers = torch.nn.ModuleList([BatchNormLinear(self.all_dims[i], classes, device=\"cuda\") for i in range(len(self.all_dims))])\n",
    "\n",
    "    def prepare_input(self, x):\n",
    "        x = self.multichannel_fn(x)\n",
    "        x = F.interpolate(x, size=(224, 224), mode=\"bicubic\")\n",
    "        x = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406] * (x.shape[1] // 3), std=[0.229, 0.224, 0.225] * (x.shape[1] // 3))(x)\n",
    "        return x\n",
    "\n",
    "    def forward_until(self, x, layer_id):\n",
    "        x = self.prepare_input(x)\n",
    "\n",
    "        for l in range(layer_id):\n",
    "            if list(x.shape)[1:] == [2048, 1, 1]:\n",
    "                x = x.reshape([-1, 2048])\n",
    "\n",
    "            x = self.layer_operations[l](x)\n",
    "        return x\n",
    "\n",
    "    def forward_after(self, x, layer_id):\n",
    "        x = self.prepare_input(x)\n",
    "\n",
    "        for l in range(layer_id, len(self.layer_operations)):\n",
    "            if list(x.shape)[1:] == [2048, 1, 1]:\n",
    "                x = x.reshape([-1, 2048])\n",
    "\n",
    "            x = self.layer_operations[l](x)\n",
    "        return x\n",
    "\n",
    "    def predict_from_layer(self, x, l):\n",
    "        x = self.forward_until(x, l)\n",
    "        x = x.reshape([x.shape[0], -1])\n",
    "        return self.linear_layers[l](x)\n",
    "\n",
    "    def predict_from_several_layers(self, x, layers):\n",
    "        x = self.prepare_input(x)\n",
    "\n",
    "        outputs = dict()\n",
    "\n",
    "        outputs[0] = self.linear_layers[0](x.reshape([x.shape[0], -1]))\n",
    "\n",
    "        for l in range(len(self.layer_operations)):\n",
    "            if list(x.shape)[1:] == [2048, 1, 1]:\n",
    "                x = x.reshape([-1, 2048])\n",
    "\n",
    "            x = self.layer_operations[l](x)\n",
    "\n",
    "            if l in layers:\n",
    "                outputs[l + 1] = self.linear_layers[l + 1](x.reshape([x.shape[0], -1]))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "resnet152_wrapper = WrapModelForResNet152(model.imported_model, make_multichannel_input, classes=classes) # <--------- this usually breaks\n",
    "resnet152_wrapper.multichannel_fn = make_multichannel_input\n",
    "resnet152_wrapper = resnet152_wrapper.to(\"cuda\")\n",
    "\n",
    "for layer_i in range(53):\n",
    "    print(f\"layer={layer_i} {resnet152_wrapper.predict_from_layer(torch.Tensor(np.zeros((2,3,32,32))).cuda(),layer_i).shape}\")\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, model, layer_i):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.model = model\n",
    "        self.layer_i = layer_i\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model.predict_from_layer(inputs, self.layer_i)\n",
    "\n",
    "backbone_model = copy.deepcopy(resnet152_wrapper)\n",
    "del resnet152_wrapper\n",
    "\n",
    "# only training some layers to save time -- super early ones are badon anything harder than CIFAR-10\n",
    "layers_to_use = [20, 30, 35, 40, 45, 50, 52]\n",
    "\n",
    "lr = 3.3e-5  # random stuff again\n",
    "epochs = 1\n",
    "batch_size = 64  # for CUDA RAM reasons\n",
    "\n",
    "mode = \"train\"\n",
    "backbone_model.eval()\n",
    "\n",
    "linear_model = LinearNet(backbone_model, 5).to(\"cuda\")  # just to have it ready\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "linear_layers_collected_dict = dict()\n",
    "\n",
    "for layer_i in reversed(layers_to_use):\n",
    "    print(f\"///////// layer={layer_i} ///////////\")\n",
    "\n",
    "    linear_model.layer_i = layer_i\n",
    "    linear_model.fixed_mode = \"train\"\n",
    "\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    robust_accs = []\n",
    "    clean_accs = []\n",
    "    actual_robust_accs = []\n",
    "\n",
    "    all_models = []\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    linear_model = train_model(\n",
    "        linear_model,\n",
    "        images_train_np[:],\n",
    "        labels_train_np[:],\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        optimizer_in=optim.Adam,\n",
    "        batch_size=batch_size,\n",
    "        mode=mode,\n",
    "        subset_only=linear_model.model.linear_layers[layer_i].parameters(),  # just the linear projection\n",
    "        use_adversarial_training=False,\n",
    "        adversarial_epsilon=None,\n",
    "    )\n",
    "\n",
    "    linear_layers_collected_dict[layer_i] = copy.deepcopy(backbone_model.linear_layers[layer_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
