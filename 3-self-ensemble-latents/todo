we want to show how much classes have been "moved" by the attack

- take ~100 unperturbed images from each class (balanced sample)
- for subset of layers (same as linear probes): forward to layer, then dump latents instead of linear probe -> stack latents for all images
- repeat also with perturbed images (masks)

plot:

- make tsne / umap plot
- only fit to unperturbed images, not to perturbed images: https://umap-learn.readthedocs.io/en/latest/transform.html
- use color/shape to encode whether they're perturbed/unperturbed and the class
